
<h2>Data Modeling</h2>
<p>
Based on this data, we can see it is a text mining task and also a classification task. We need to understand text and also use other features to label each data entry.

<ul>
	<li>Build semantic space</li>
	<li>Generate topics which can be used to define news</li>
	<li>Generate sample set for a given news</li>
	<li>Remove Outliers</li>
	<li>KNN Classification</li>
	<li>Adjust parameters for better results</li>
	<li>Interpret results</li>
</p>
<p>
	For text mining, we can have two solutions
	<ul>
		<li>bag of words</li>
		<p>we ignore the association between words in the article. We only care about the frequency of the words.</p>
		<li>latent semantic analysis</li>
		<p>we consider each article is the context of the words. the meaning of each word is based on the content of the current article. We project words into the semantic space of the current article. All the content of the article is reduced to several topics.</p>
	</ul>
	For popularity prediction, we choose Latent semantic analysis. 
</p>
<p>
	For other features, such as Source, SentimentTitle, SentimentHeadline, we can directly use them to make prediction. 
	Before we use choose classification algoritm, we evaluate the significance of the features with information gain. We get the following result.
	<table style="border: 1px solid black">
		<tr><td>Website</td><td>Source</td><td>SentimentTitle</td><td>SentimentHeadline</td></tr>
		<tr><td>Facebook</td><td>0.6427983828436333></td><td>0.682137527933072</td><td>0.6065400706568865</td></tr>
		<tr><td>GooglePlus</td><td>0.4545358118900283></td><td>0.48596147409162366</td><td>0.4117329019171993</td></tr>
		<tr><td>LinkedIn</td><td>0.5177361250103715</td><td>0.5575869048549802</td><td>0.4672467847269911</td></tr>
	</table>
	The information gain shows use that these features are not very strongly related to targets. We don't have many features to choose. We don't have domain knowledge to add extra information into the feature set, either. We need to improve the quality of the raw data as much as possible.

	Our solution is that we not only use latent semantic analysis to make the text feature more meaningful, also, based on the new data, we only use similar news to predict the label of the new data. In other words, we create a specific data set for each news we are going to classify. The data modeling process can be generalized but each model we generated is specified for the a particular news. We don't create a general model for all of the news, but, each model can classify the particular news better.

</p>














